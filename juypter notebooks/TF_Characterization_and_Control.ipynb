{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g30eXP36qXjA"
      },
      "source": [
        "<H1> Example on using the datasets for quantum characterization and control </H1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2C0aqWLyqXjD"
      },
      "outputs": [],
      "source": [
        "# preample\n",
        "import zipfile\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from typing import Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KKVDS6pMqXjE"
      },
      "outputs": [],
      "source": [
        "datalist = [\n",
        "'G_1q_X',\n",
        "# 'G_1q_XY',\n",
        "# 'G_1q_XY_XZ_N1N5',\n",
        "# 'G_1q_XY_XZ_N1N6',\n",
        "# 'G_1q_XY_XZ_N3N6',\n",
        "# 'G_1q_X_Z_N1',\n",
        "# 'G_1q_X_Z_N2',\n",
        "# 'G_1q_X_Z_N3',\n",
        "# 'G_1q_X_Z_N4',\n",
        "# 'G_2q_IX-XI_IZ-ZI_N1-N6',\n",
        "# 'G_2q_IX-XI-XX',\n",
        "# 'G_2q_IX-XI-XX_IZ-ZI_N1-N5',\n",
        "# 'G_2q_IX-XI-XX_IZ-ZI_N1-N5',\n",
        "# 'S_1q_X',\n",
        "# 'S_1q_XY',\n",
        "# 'S_1q_XY_XZ_N1N5',\n",
        "# 'S_1q_XY_XZ_N1N6',\n",
        "# 'S_1q_XY_XZ_N3N6',\n",
        "# 'S_1q_X_Z_N1',\n",
        "# 'S_1q_X_Z_N2',\n",
        "# 'S_1q_X_Z_N3',\n",
        "# 'S_1q_X_Z_N4',\n",
        "# 'S_2q_IX-XI_IZ-ZI_N1-N6',\n",
        "# 'S_2q_IX-XI-XX',\n",
        "# 'S_2q_IX-XI-XX_IZ-ZI_N1-N5',\n",
        "# 'S_2q_IX-XI-XX_IZ-ZI_N1-N6',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QR5iBorFqXjF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "G_1q_X\n",
            "G_1q_X_D\n"
          ]
        }
      ],
      "source": [
        "'''Create two strings, one for each of the undistorted and distorted datasets.'''\n",
        "data1 = datalist[0]\n",
        "data2 = data1 + '_D'\n",
        "print(data1)\n",
        "print(data2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_2ii5CF1qXjG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/mnt/c/Users/ChrisWiseXPSLocal/GitHub/QDataSet\n"
          ]
        }
      ],
      "source": [
        "'''Set the working directory to the location of the datasets, example below.'''\n",
        "print(os.getcwd())\n",
        "os.chdir(f'./QuantumDS/{data1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk47O1tEqXjM"
      },
      "source": [
        "## Using the $V_O$ operators in a calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "n0XfHjkbqXjM"
      },
      "outputs": [],
      "source": [
        "def load_Vo_dataset(dataset_name: str, num_examples: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Load the dataset of pulses and Vo operators.\n",
        "\n",
        "    Args:\n",
        "        dataset_name: Name of the dataset.\n",
        "        num_examples: Number of examples to load.\n",
        "\n",
        "    Returns:\n",
        "        pulses: Array of pulses.\n",
        "        Vx: Array of X Vo operators.\n",
        "        Vy: Array of Y Vo operators.\n",
        "        Vz: Array of Z Vo operators.\n",
        "    \"\"\"\n",
        "    pulses = np.zeros((num_examples, 1024), dtype=np.complex64)\n",
        "    Vx = np.zeros((num_examples, 2, 2), dtype=np.complex64)\n",
        "    Vy = np.zeros((num_examples, 2, 2), dtype=np.complex64)\n",
        "    Vz = np.zeros((num_examples, 2, 2), dtype=np.complex64)\n",
        "\n",
        "    with zipfile.ZipFile(f\"{dataset_name}.zip\", mode=\"r\") as fzip:\n",
        "        for index, fname in enumerate(fzip.namelist()[:num_examples]):\n",
        "            with fzip.open(fname, \"r\") as f:\n",
        "                data = pickle.load(f)\n",
        "                pulses[index, :] = data[\"pulses\"][0, :, 0].reshape(1024,)\n",
        "                Vx[index], Vy[index], Vz[index] = data[\"Vo_operator\"]\n",
        "                \n",
        "    return pulses, Vx, Vy, Vz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "VRqaamMBqXjN"
      },
      "outputs": [],
      "source": [
        "# define the dataset parameters\n",
        "dataset_name = data2  # \"G_1q_XY_XZ_N1N5_D\" # dataset name\n",
        "num_ex = 3  # number of examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "2_Bv3VDcqXjN"
      },
      "outputs": [],
      "source": [
        "pulses, Vx, Vy, Vz, = load_Vo_dataset(dataset_name, num_ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "t1qOvOzjqXjN",
        "outputId": "a259ddb5-db82-4743-f7c7-34552f0091b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 1024)\n",
            "(3, 2, 2)\n",
            "(3, 2, 2)\n",
            "(3, 2, 2)\n"
          ]
        }
      ],
      "source": [
        "print(pulses.shape)\n",
        "print(Vx.shape)\n",
        "print(Vy.shape)\n",
        "print(Vz.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhRDQANNqXjO",
        "outputId": "ff9a6bcf-3a2c-4bba-b95a-143320046fd8"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "W-7DdpdsqXjO",
        "outputId": "11aa19aa-021f-4ba7-f79c-d7eedbc2b2c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-13 14:29:32.710350: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-13 14:29:37.831856: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2023-02-13 14:29:37.831908: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-02-13 14:30:05.576803: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-02-13 14:30:05.584676: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-02-13 14:30:05.584698: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mK\u001b[39;00m\n\u001b[1;32m      2\u001b[0m embed_dim \u001b[39m=\u001b[39m \u001b[39m1024\u001b[39m\n\u001b[1;32m      4\u001b[0m input_layer \u001b[39m=\u001b[39m K\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(\u001b[39mNone\u001b[39;00m, axnum))\n",
            "File \u001b[0;32m/mnt/c/Users/ChrisWiseXPSLocal/GitHub/QDataSet/venv/lib/python3.10/site-packages/tensorflow/__init__.py:470\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_current_module, \u001b[39m\"\u001b[39m\u001b[39mkeras\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    469\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 470\u001b[0m     _keras\u001b[39m.\u001b[39;49m_load()\n\u001b[1;32m    471\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    472\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
            "File \u001b[0;32m/mnt/c/Users/ChrisWiseXPSLocal/GitHub/QDataSet/venv/lib/python3.10/site-packages/tensorflow/python/util/lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n\u001b[1;32m     44\u001b[0m \u001b[39m# Emit a warning if one was specified\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
            "File \u001b[0;32m/mnt/c/Users/ChrisWiseXPSLocal/GitHub/QDataSet/venv/lib/python3.10/site-packages/keras/__init__.py:21\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
            "File \u001b[0;32m/mnt/c/Users/ChrisWiseXPSLocal/GitHub/QDataSet/venv/lib/python3.10/site-packages/keras/models/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
            "File \u001b[0;32m/mnt/c/Users/ChrisWiseXPSLocal/GitHub/QDataSet/venv/lib/python3.10/site-packages/keras/engine/functional.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m layout_map \u001b[39mas\u001b[39;00m layout_map_lib\n",
            "File \u001b[0;32m/mnt/c/Users/ChrisWiseXPSLocal/GitHub/QDataSet/venv/lib/python3.10/site-packages/tensorflow/_api/v2/compat/__init__.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m v1\n\u001b[0;32m---> 38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m v2\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m forward_compatibility_horizon\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m forward_compatible\n",
            "File \u001b[0;32m/mnt/c/Users/ChrisWiseXPSLocal/GitHub/QDataSet/venv/lib/python3.10/site-packages/tensorflow/_api/v2/compat/v2/__init__.py:39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dtypes\n\u001b[0;32m---> 39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m errors\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m experimental\n\u001b[1;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m feature_column\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow.keras as K\n",
        "embed_dim = 1024\n",
        "\n",
        "input_layer = K.Input(shape=(None, axnum))\n",
        "embedding_layer = K.layers.Embedding(input_dim=axnum, output_dim=embed_dim)(\n",
        "    input_layer\n",
        ")\n",
        "transformer_layer = K.layers.Transformer(\n",
        "    num_heads=num_heads, feed_forward_dim=feed_forward_dim, activation=\"relu\"\n",
        ")(embedding_layer)\n",
        "output_layer = K.layers.Reshape((axnum3, axnum3))(transformer_layer)\n",
        "ml_model = K.Model(input_layer, output_layer)\n",
        "ml_model.compile(optimizer=K.optimizers.Adam(), loss=\"mse\")\n",
        "ml_model.fit(pulses, [Vx, Vy, Vz], epochs=10, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKOrO90VqXjO"
      },
      "source": [
        "## Model the effect of control distortions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BW4HxJPPqXjP"
      },
      "outputs": [],
      "source": [
        "# define the dataset parameters\n",
        "dataset_name    = data2 #\"G_1q_XY_XZ_N1N5_D\" # dataset name\n",
        "num_training_ex = 7                   # number of training examples\n",
        "num_testing_ex  = 3                   # number of testing examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crAqOEoEqXjP"
      },
      "outputs": [],
      "source": [
        "# load the dataset\n",
        "training_input, training_target, testing_input, testing_target = load_dataset(dataset_name, num_training_ex, num_testing_ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCDjc1_SqXjP",
        "outputId": "0b15ee62-b535-4eeb-a00f-70a579e062df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7, 1024, 1) (7, 18) (3, 1024, 1) (3, 18)\n"
          ]
        }
      ],
      "source": [
        "print(training_input.shape, training_target.shape, testing_input.shape, testing_target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1fPLTukqXjP",
        "outputId": "49d04e02-b196-43d5-cfdd-3b46d5cf525b"
      },
      "outputs": [],
      "source": [
        "'''Set shape parameters based on shape of inputs and outputs.'''\n",
        "axnum = training_input.shape[2]\n",
        "lstmout = training_target.shape[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eid1-VYwqXjQ",
        "outputId": "0f8a3ec0-b685-4aff-8de1-8e3f7c3c5436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3332 - val_loss: 0.3333\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 505ms/step - loss: 0.3328 - val_loss: 0.3334\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 518ms/step - loss: 0.3324 - val_loss: 0.3335\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 0.3320 - val_loss: 0.3336\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 514ms/step - loss: 0.3316 - val_loss: 0.3337\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 503ms/step - loss: 0.3311 - val_loss: 0.3338\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 592ms/step - loss: 0.3306 - val_loss: 0.3340\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.3302 - val_loss: 0.3341\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 0.3297 - val_loss: 0.3343\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 540ms/step - loss: 0.3291 - val_loss: 0.3345\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e56dd66b0>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use the dataset for training and testing an ML algorithm\n",
        "\n",
        "#############################################\n",
        "##          PUT YOUR CODE HERE             ##\n",
        "\n",
        "# trained_model = my_training_function(training_input, training_target)\n",
        "\n",
        "# performance   = my_testing_function(trained_model, testing_input, testing_target)\n",
        "\n",
        "### Below is an example using tensorflow  ###\n",
        "\n",
        "import tensorflow.keras as K\n",
        "\n",
        "input_layer   = K.Input(shape=(None, axnum))\n",
        "\n",
        "output_layer  = K.layers.LSTM(lstmout, return_sequences=False)(input_layer)\n",
        "\n",
        "ml_model      = K.Model(input_layer, output_layer)\n",
        "\n",
        "ml_model.compile(optimizer=K.optimizers.Adam(), loss='mse')\n",
        "\n",
        "ml_model.fit(training_input, training_target, epochs=10, validation_data = (testing_input, testing_target))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pIscMDvqXjQ"
      },
      "source": [
        "## Learning a controller for a quantum system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bya6ZuknqXjQ"
      },
      "outputs": [],
      "source": [
        "# define the dataset parameters\n",
        "dataset_name    = data1 #\"G_1q_XY_XZ_N1N5\"   # dataset name\n",
        "num_training_ex = 7                   # number of training examples\n",
        "num_testing_ex  = 3                   # number of testing examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-T5MWwGqXjQ"
      },
      "outputs": [],
      "source": [
        "# load the dataset [inputs and targets are echanged for quantum control problem, this is the inverse of the \n",
        "# characterization problem]\n",
        "training_target, training_input, testing_target, testing_input  = load_dataset(dataset_name, num_training_ex, num_testing_ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa9vC8OOqXjR",
        "outputId": "1b4f6837-8ca4-492f-a649-32a468fe98d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7, 18) (7, 1024, 1) (3, 18) (3, 1024, 1)\n"
          ]
        }
      ],
      "source": [
        "print(training_input.shape, training_target.shape, testing_input.shape, testing_target.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOpFUhzcqXjR"
      },
      "outputs": [],
      "source": [
        "'''Set shape parameters based on shape of inputs and outputs.'''\n",
        "axnum4 = training_input.shape[1]\n",
        "axnum5 = training_target.shape[1]\n",
        "axnum6 = training_target.shape[2]\n",
        "axnum7 = axnum5 * axnum6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AYkya-cqXjR",
        "outputId": "e7549d7d-a130-4d2c-a7f8-6bdf8ab7797e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 439.0493 - val_loss: 523.0949\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 438.9573 - val_loss: 523.0969\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 438.8654 - val_loss: 523.0988\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 438.7735 - val_loss: 523.1008\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 438.6816 - val_loss: 523.1027\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 438.5898 - val_loss: 523.1047\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 438.4980 - val_loss: 523.1068\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 438.4063 - val_loss: 523.1088\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 438.3147 - val_loss: 523.1108\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 438.2230 - val_loss: 523.1129\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e56b98100>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use the dataset for training and testing an ML algorithm\n",
        "\n",
        "#############################################\n",
        "##          PUT YOUR CODE HERE             ##\n",
        "\n",
        "# trained_model = my_training_function(training_input, training_target)\n",
        "\n",
        "# performance   = my_testing_function(trained_model, testing_input, testing_target)\n",
        "\n",
        "### Below is an example using tensorflow  ###\n",
        "\n",
        "import tensorflow.keras as K\n",
        "\n",
        "input_layer   = K.Input(shape=(axnum4))\n",
        "\n",
        "output_layer  = K.layers.Reshape((axnum5,axnum6))( K.layers.Dense(axnum7)(input_layer) )\n",
        "\n",
        "ml_model      = K.Model(input_layer, output_layer)\n",
        "\n",
        "ml_model.compile(optimizer=K.optimizers.Adam(), loss='mse')\n",
        "\n",
        "ml_model.fit(training_input, training_target, epochs=10, validation_data = (testing_input, testing_target))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TF Characterization_and_Control.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "f886a96e898f192a82292c66184b9e30880872026f5a12b6c6564d50420f8345"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
