{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g30eXP36qXjA"
      },
      "source": [
        "<H1> Example on using the datasets for quantum characterization and control </H1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2C0aqWLyqXjD"
      },
      "outputs": [],
      "source": [
        "# preample\n",
        "import zipfile\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Y_KVq8FtqY7m"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The datalist below lists each different dataset category.\\nEach category comprises two compressed files:\\n(a) one for the non-distorted examples; and\\n(b) another for the distorted examples.\\n\\nEach dataset is stored in a folder corresponding to its category on Cloudstor.\\nThere are 52 datasets in the QDataSet and 26 categories.\\n\\n\\nTo run the code:\\n1. Download both the distorted and non-distorted datasets from Cloudstor\\n(assuming both are to be used);\\n2. To select a dataset for the model (e.g. G_1q_X), uncomment the dataset\\nin the dataset list below.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''The datalist below lists each different dataset category.\n",
        "Each category comprises two compressed files:\n",
        "(a) one for the non-distorted examples; and\n",
        "(b) another for the distorted examples.\n",
        "\n",
        "Each dataset is stored in a folder corresponding to its category on Cloudstor.\n",
        "There are 52 datasets in the QDataSet and 26 categories.\n",
        "\n",
        "\n",
        "To run the code:\n",
        "1. Download both the distorted and non-distorted datasets from Cloudstor\n",
        "(assuming both are to be used);\n",
        "2. To select a dataset for the model (e.g. G_1q_X), uncomment the dataset\n",
        "in the dataset list below.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KKVDS6pMqXjE"
      },
      "outputs": [],
      "source": [
        "datalist = [\n",
        "'G_1q_X',\n",
        "# 'G_1q_XY',\n",
        "# 'G_1q_XY_XZ_N1N5',\n",
        "# 'G_1q_XY_XZ_N1N6',\n",
        "# 'G_1q_XY_XZ_N3N6',\n",
        "# 'G_1q_X_Z_N1',\n",
        "# 'G_1q_X_Z_N2',\n",
        "# 'G_1q_X_Z_N3',\n",
        "# 'G_1q_X_Z_N4',\n",
        "# 'G_2q_IX-XI_IZ-ZI_N1-N6',\n",
        "# 'G_2q_IX-XI-XX',\n",
        "# 'G_2q_IX-XI-XX_IZ-ZI_N1-N5',\n",
        "# 'G_2q_IX-XI-XX_IZ-ZI_N1-N5',\n",
        "# 'S_1q_X',\n",
        "# 'S_1q_XY',\n",
        "# 'S_1q_XY_XZ_N1N5',\n",
        "# 'S_1q_XY_XZ_N1N6',\n",
        "# 'S_1q_XY_XZ_N3N6',\n",
        "# 'S_1q_X_Z_N1',\n",
        "# 'S_1q_X_Z_N2',\n",
        "# 'S_1q_X_Z_N3',\n",
        "# 'S_1q_X_Z_N4',\n",
        "# 'S_2q_IX-XI_IZ-ZI_N1-N6',\n",
        "# 'S_2q_IX-XI-XX',\n",
        "# 'S_2q_IX-XI-XX_IZ-ZI_N1-N5',\n",
        "# 'S_2q_IX-XI-XX_IZ-ZI_N1-N6',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QR5iBorFqXjF"
      },
      "outputs": [],
      "source": [
        "'''Create two strings, one for each of the undistorted and distorted datasets.'''\n",
        "data1 = datalist[0]\n",
        "data2 = data1 + '_D'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "aF0gCIRVqXjF",
        "outputId": "bd3f77f1-3cf4-491a-80a1-6c7a99071919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "G_1q_X\n",
            "G_1q_X_D\n"
          ]
        }
      ],
      "source": [
        "'''Check strings created correction'''\n",
        "print(data1)\n",
        "print(data2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_2ii5CF1qXjG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/mnt/c/Users/ChrisWiseXPSLocal/GitHub/QDataSet/QuantumDS\n",
            "['.owncloudsync.log', 'G_1q_X']\n"
          ]
        }
      ],
      "source": [
        "'''Set the working directory to the location of the datasets, example below.'''\n",
        "#pirnt current working directory\n",
        "print(os.getcwd())\n",
        "print(os.listdir())\n",
        "os.chdir(f'./{data1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj4uDe_LqXjI"
      },
      "source": [
        "## Characterization of an open quantum system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Fw4HbDprqXjJ"
      },
      "outputs": [],
      "source": [
        "'''Define a function to extract the data from the dataset.'''\n",
        "\n",
        "def load_dataset(dataset_name, num_training_ex, num_testing_ex):\n",
        "    \n",
        "    # initialize empt lists for storing the data\n",
        "    data_input         = []\n",
        "    data_target        = []\n",
        "    \n",
        "    # 1) unzip the dataset zipfile\n",
        "    fzip               = zipfile.ZipFile(\"%s.zip\"%dataset_name, mode='r')\n",
        "    \n",
        "    # loop over example files\n",
        "    #########################################################\n",
        "    for idx_ex in range(num_training_ex + num_testing_ex):\n",
        "    \n",
        "        # 2) extract the example file from the dataset \n",
        "        fname = \"%s_ex_%d\"%(dataset_name, idx_ex)\n",
        "        fzip.extract( fname )\n",
        "    \n",
        "        # 3) load the example file\n",
        "        f     = open(fname,  \"rb\")\n",
        "        data  = pickle.load(f)\n",
        "    \n",
        "        # 4) extract the useful information from the example file:\n",
        "        \n",
        "        # For noise spectroscopy, we need to extract a set of control pulse and the \n",
        "        # correpsonding informationally-complete observables\n",
        "        \n",
        "        # add the pair of input and target to the corresponding lists\n",
        "        data_input.append( data[\"pulses\"][0:1, :, 0, :])\n",
        "        data_target.append( data[\"expectations\"] )\n",
        "        \n",
        "        # 5) close and delete the example file\n",
        "        f.close()\n",
        "        os.remove(fname)\n",
        "    #########################################################\n",
        "    # 5) close the dataset zipfile\n",
        "    fzip.close()\n",
        "    \n",
        "    # 6) split the data into training and testing\n",
        "    data_input            = np.concatenate(data_input, axis=0)\n",
        "    data_target           = np.concatenate(data_target, axis=0)\n",
        "    \n",
        "    training_input        = data_input[0:num_training_ex, :]\n",
        "    testing_input         = data_input[num_training_ex:num_training_ex+num_testing_ex, :]\n",
        "    \n",
        "    training_target       = data_target[0:num_training_ex, :]\n",
        "    testing_target        = data_target[num_training_ex:num_training_ex+num_testing_ex, :]\n",
        "    \n",
        "    return training_input, training_target, testing_input, testing_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3J58CjoUqXjK"
      },
      "outputs": [],
      "source": [
        "'''Define the dataset parameters'''\n",
        "dataset_name    = data1#\"G_1q_XY_XZ_N1N5\" # dataset name\n",
        "num_training_ex = 7                 # number of training examples\n",
        "num_testing_ex  = 3                 # number of testing examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "z0flCyx6qXjK"
      },
      "outputs": [],
      "source": [
        "# load the dataset\n",
        "training_input, training_target, testing_input, testing_target = load_dataset(dataset_name, num_training_ex, num_testing_ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "EMBBIsCeqXjL",
        "outputId": "02f42ea5-cdc0-4c60-b302-35ce8d30e913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7, 1024, 1) (7, 18) (3, 1024, 1) (3, 18)\n"
          ]
        }
      ],
      "source": [
        "'''Inspect the shape of the training and test dataframes (if need be).'''\n",
        "print(training_input.shape, training_target.shape, testing_input.shape, testing_target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "oV629oSWqXjL",
        "outputId": "66b0dc25-fc41-434b-80eb-ef36bf53e685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 18\n"
          ]
        }
      ],
      "source": [
        "'''Set input parameter shape based on number of axes along which controls / noise is applied.'''\n",
        "axnum = training_input.shape[2]\n",
        "axnum2 = training_target.shape[1]\n",
        "print(axnum, axnum2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yZC1BYFjqXjM",
        "outputId": "e6e3b156-7565-4977-d48e-1720a19dfcc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-07 17:15:50.800789: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-07 17:15:57.130117: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2023-02-07 17:15:57.130245: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-02-07 17:16:30.473508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-02-07 17:16:30.480786: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-02-07 17:16:30.480808: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-07 17:17:49.082707: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2023-02-07 17:17:49.086411: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2023-02-07 17:17:49.086784: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ChrisWiseXPS13): /proc/driver/nvidia/version does not exist\n",
            "2023-02-07 17:17:49.092759: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3332 - val_loss: 0.3332\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 564ms/step - loss: 0.3330 - val_loss: 0.3332\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 503ms/step - loss: 0.3329 - val_loss: 0.3331\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.3327 - val_loss: 0.3331\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3326 - val_loss: 0.3331\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.3324 - val_loss: 0.3330\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.3322 - val_loss: 0.3330\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.3321 - val_loss: 0.3329\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.3319 - val_loss: 0.3328\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 646ms/step - loss: 0.3317 - val_loss: 0.3327\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c147b4eb0>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use the dataset for training and testing an ML algorithm\n",
        "\n",
        "#############################################\n",
        "##          PUT YOUR CODE HERE             ##\n",
        "\n",
        "# trained_model  = my_training_function(training_input, training_target)\n",
        "\n",
        "# performance    = my_testing_function(trained_model, testing_input, testing_target)\n",
        "\n",
        "# noise_spectrum = estimate_noise(trained_model)\n",
        "\n",
        "### Below is an example using tensorflow  ###\n",
        "\n",
        "import tensorflow.keras as K\n",
        "\n",
        "input_layer   = K.Input(shape=(None, axnum))\n",
        "\n",
        "output_layer  = K.layers.LSTM(axnum2, return_sequences=False)(input_layer)\n",
        "\n",
        "ml_model      = K.Model(input_layer, output_layer)\n",
        "\n",
        "ml_model.compile(optimizer=K.optimizers.Adam(), loss='mse')\n",
        "\n",
        "ml_model.fit(training_input, training_target, epochs=10, validation_data = (testing_input, testing_target))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk47O1tEqXjM"
      },
      "source": [
        "## Using the $V_O$ operators in a calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "n0XfHjkbqXjM"
      },
      "outputs": [],
      "source": [
        "'''Define a function to extract the data from the dataset.'''\n",
        "def load_Vo_dataset(dataset_name, num_ex):\n",
        "    \n",
        "    # initialize empt lists for storing the data\n",
        "    pulses         = []\n",
        "    VX             = []\n",
        "    VY             = []\n",
        "    VZ             = []\n",
        "    # 1) unzip the dataset zipfile\n",
        "    fzip               = zipfile.ZipFile(\"%s.zip\"%dataset_name, mode='r')\n",
        "    \n",
        "    # loop over example files\n",
        "    #########################################################\n",
        "    for idx_ex in range(num_ex):\n",
        "    \n",
        "        # 2) extract the example file from the dataset \n",
        "        fname = \"%s_ex_%d\"%(dataset_name, idx_ex)\n",
        "        fzip.extract( fname )\n",
        "    \n",
        "        # 3) load the example file\n",
        "        f     = open(fname,  \"rb\")\n",
        "        data  = pickle.load(f)\n",
        "    \n",
        "        # 4) extract the useful information from the example file:\n",
        "        \n",
        "        # For noise spectroscopy, we need to extract a set of control pulse and the \n",
        "        # correpsonding informationally-complete observables\n",
        "        \n",
        "        # add the pair of input and target to the corresponding lists\n",
        "        pulses.append( data[\"pulses\"][0:1, :, 0, :])\n",
        "        VX.append( data[\"Vo_operator\"][0] )\n",
        "        VY.append( data[\"Vo_operator\"][1] )\n",
        "        VZ.append( data[\"Vo_operator\"][2] )\n",
        "        \n",
        "        # 5) close and delete the example file\n",
        "        f.close()\n",
        "        os.remove(fname)\n",
        "    #########################################################\n",
        "    # 5) close the dataset zipfile\n",
        "    fzip.close()\n",
        "    \n",
        "    # 6) split the data into training and testing\n",
        "    pulses            = np.concatenate(pulses, axis=0)\n",
        "    VX                = np.concatenate(VX, axis=0)\n",
        "    VY                = np.concatenate(VY, axis=0)\n",
        "    VZ                = np.concatenate(VZ, axis=0)   \n",
        "    \n",
        "    return pulses, VX, VY, VZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VRqaamMBqXjN"
      },
      "outputs": [],
      "source": [
        "# define the dataset parameters\n",
        "dataset_name    = data2 #\"G_1q_XY_XZ_N1N5_D\" # dataset name\n",
        "num_ex = 7                            # number of examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "2_Bv3VDcqXjN"
      },
      "outputs": [],
      "source": [
        "pulses, VX, VY, VZ = load_Vo_dataset(dataset_name, num_ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "t1qOvOzjqXjN",
        "outputId": "a259ddb5-db82-4743-f7c7-34552f0091b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7, 1024, 1) (7, 2, 2) (7, 2, 2) (7, 2, 2)\n"
          ]
        }
      ],
      "source": [
        "print(pulses.shape, VX.shape, VY.shape, VZ.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "MhRDQANNqXjO",
        "outputId": "ff9a6bcf-3a2c-4bba-b95a-143320046fd8"
      },
      "outputs": [],
      "source": [
        "'''Set input parameter shape based on number of qubits and set corresponding shape of flattened \n",
        "tensor for input into LSTM parameter.'''\n",
        "# axnum = training_input.shape[2]\n",
        "axnum3 = VX.shape[2]\n",
        "lstmflat = axnum3 **2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "I9TV7ta6qXjO"
      },
      "outputs": [],
      "source": [
        "# use the Vo in a calculation\n",
        "\n",
        "#############################################\n",
        "##          PUT YOUR CODE HERE             ##\n",
        "\n",
        "# result = my_calculation(pulses, VX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "W-7DdpdsqXjO",
        "outputId": "11aa19aa-021f-4ba7-f79c-d7eedbc2b2c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4999 - val_loss: 0.4986\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.4986 - val_loss: 0.4972\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.4972 - val_loss: 0.4959\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 517ms/step - loss: 0.4959 - val_loss: 0.4946\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.4946 - val_loss: 0.4932\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.4932 - val_loss: 0.4919\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.4919 - val_loss: 0.4905\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 504ms/step - loss: 0.4905 - val_loss: 0.4891\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 517ms/step - loss: 0.4891 - val_loss: 0.4878\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.4878 - val_loss: 0.4864\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8bf6a7b2b0>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train an ML model to learn Vo\n",
        "\n",
        "#############################################\n",
        "##          PUT YOUR CODE HERE             ##\n",
        "\n",
        "# trained_model = my_training_function(training_input=pulses[0:100,;], training_target=VX[0:100, :])\n",
        "\n",
        "# performance   = my_testing_function(trained_model, testing_input=pulses[100:,:], testing_target=Vx[100:,:])\n",
        "\n",
        "### Below is an example using tensorflow  ###\n",
        "\n",
        "import tensorflow.keras as K\n",
        "\n",
        "input_layer   = K.Input(shape=(None, axnum))\n",
        "\n",
        "output_layer  = K.layers.Reshape((axnum3,axnum3)) (  K.layers.LSTM(lstmflat, return_sequences=False)(input_layer) )\n",
        "\n",
        "ml_model      = K.Model(input_layer, output_layer)\n",
        "\n",
        "ml_model.compile(optimizer=K.optimizers.Adam(), loss='mse')\n",
        "\n",
        "ml_model.fit(pulses, VX, epochs=10, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKOrO90VqXjO"
      },
      "source": [
        "## Model the effect of control distortions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "BW4HxJPPqXjP"
      },
      "outputs": [],
      "source": [
        "# define the dataset parameters\n",
        "dataset_name    = data2 #\"G_1q_XY_XZ_N1N5_D\" # dataset name\n",
        "num_training_ex = 7                   # number of training examples\n",
        "num_testing_ex  = 3                   # number of testing examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "crAqOEoEqXjP"
      },
      "outputs": [],
      "source": [
        "# load the dataset\n",
        "training_input, training_target, testing_input, testing_target = load_dataset(dataset_name, num_training_ex, num_testing_ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "qCDjc1_SqXjP",
        "outputId": "0b15ee62-b535-4eeb-a00f-70a579e062df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7, 1024, 1) (7, 18) (3, 1024, 1) (3, 18)\n"
          ]
        }
      ],
      "source": [
        "print(training_input.shape, training_target.shape, testing_input.shape, testing_target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "h1fPLTukqXjP",
        "outputId": "49d04e02-b196-43d5-cfdd-3b46d5cf525b"
      },
      "outputs": [],
      "source": [
        "'''Set shape parameters based on shape of inputs and outputs.'''\n",
        "axnum = training_input.shape[2]\n",
        "lstmout = training_target.shape[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Eid1-VYwqXjQ",
        "outputId": "0f8a3ec0-b685-4aff-8de1-8e3f7c3c5436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3332 - val_loss: 0.3336\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 643ms/step - loss: 0.3328 - val_loss: 0.3341\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 604ms/step - loss: 0.3323 - val_loss: 0.3345\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.3318 - val_loss: 0.3351\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 0.3313 - val_loss: 0.3356\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 628ms/step - loss: 0.3308 - val_loss: 0.3363\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 602ms/step - loss: 0.3303 - val_loss: 0.3370\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 596ms/step - loss: 0.3297 - val_loss: 0.3377\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 0.3291 - val_loss: 0.3386\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 611ms/step - loss: 0.3284 - val_loss: 0.3397\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8bf6def4c0>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use the dataset for training and testing an ML algorithm\n",
        "\n",
        "#############################################\n",
        "##          PUT YOUR CODE HERE             ##\n",
        "\n",
        "# trained_model = my_training_function(training_input, training_target)\n",
        "\n",
        "# performance   = my_testing_function(trained_model, testing_input, testing_target)\n",
        "\n",
        "### Below is an example using tensorflow  ###\n",
        "\n",
        "import tensorflow.keras as K\n",
        "\n",
        "input_layer   = K.Input(shape=(None, axnum))\n",
        "\n",
        "output_layer  = K.layers.LSTM(lstmout, return_sequences=False)(input_layer)\n",
        "\n",
        "ml_model      = K.Model(input_layer, output_layer)\n",
        "\n",
        "ml_model.compile(optimizer=K.optimizers.Adam(), loss='mse')\n",
        "\n",
        "ml_model.fit(training_input, training_target, epochs=10, validation_data = (testing_input, testing_target))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pIscMDvqXjQ"
      },
      "source": [
        "## Learning a controller for a quantum system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "bya6ZuknqXjQ"
      },
      "outputs": [],
      "source": [
        "# define the dataset parameters\n",
        "dataset_name    = data1 #\"G_1q_XY_XZ_N1N5\"   # dataset name\n",
        "num_training_ex = 7                   # number of training examples\n",
        "num_testing_ex  = 3                   # number of testing examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "J-T5MWwGqXjQ"
      },
      "outputs": [],
      "source": [
        "# load the dataset [inputs and targets are echanged for quantum control problem, this is the inverse of the \n",
        "# characterization problem]\n",
        "training_target, training_input, testing_target, testing_input  = load_dataset(dataset_name, num_training_ex, num_testing_ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "sa9vC8OOqXjR",
        "outputId": "1b4f6837-8ca4-492f-a649-32a468fe98d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7, 18) (7, 1024, 1) (3, 18) (3, 1024, 1)\n"
          ]
        }
      ],
      "source": [
        "print(training_input.shape, training_target.shape, testing_input.shape, testing_target.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ZOpFUhzcqXjR"
      },
      "outputs": [],
      "source": [
        "'''Set shape parameters based on shape of inputs and outputs.'''\n",
        "axnum4 = training_input.shape[1]\n",
        "axnum5 = training_target.shape[1]\n",
        "axnum6 = training_target.shape[2]\n",
        "axnum7 = axnum5 * axnum6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "7AYkya-cqXjR",
        "outputId": "e7549d7d-a130-4d2c-a7f8-6bdf8ab7797e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 0s 497ms/step - loss: 439.1874 - val_loss: 523.2390\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 439.0955 - val_loss: 523.2410\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 439.0036 - val_loss: 523.2431\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 438.9117 - val_loss: 523.2453\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 438.8198 - val_loss: 523.2474\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 438.7280 - val_loss: 523.2495\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 438.6362 - val_loss: 523.2516\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 438.5445 - val_loss: 523.2538\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 438.4527 - val_loss: 523.2559\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 438.3611 - val_loss: 523.2582\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c147250f0>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use the dataset for training and testing an ML algorithm\n",
        "\n",
        "#############################################\n",
        "##          PUT YOUR CODE HERE             ##\n",
        "\n",
        "# trained_model = my_training_function(training_input, training_target)\n",
        "\n",
        "# performance   = my_testing_function(trained_model, testing_input, testing_target)\n",
        "\n",
        "### Below is an example using tensorflow  ###\n",
        "\n",
        "import tensorflow.keras as K\n",
        "\n",
        "input_layer   = K.Input(shape=(axnum4))\n",
        "\n",
        "output_layer  = K.layers.Reshape((axnum5,axnum6))( K.layers.Dense(axnum7)(input_layer) )\n",
        "\n",
        "ml_model      = K.Model(input_layer, output_layer)\n",
        "\n",
        "ml_model.compile(optimizer=K.optimizers.Adam(), loss='mse')\n",
        "\n",
        "ml_model.fit(training_input, training_target, epochs=10, validation_data = (testing_input, testing_target))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TF Characterization_and_Control.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "f886a96e898f192a82292c66184b9e30880872026f5a12b6c6564d50420f8345"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
